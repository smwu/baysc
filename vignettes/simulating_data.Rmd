---
title: "Simulating Data"
output: 
  rmarkdown::html_vignette:
    number_sections: yes
    toc: yes
    df_print: "paged"
bibliography: baysc.bib
vignette: >
  %\VignetteIndexEntry{Simulating Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

This vignette provides an overview of the basic data simulation capabilities provided by the `baysc` package. For a description of the main package modeling functions, please see the vignette titled, "An introduction to the baysc package". We begin by loading the package.

```{r, eval = FALSE}
# If R package `devtools` is not installed, uncomment the following line:
# `install.packages(devtools)`

# Load devtools and install baysc from GitHub
library(devtools)
devtools::install_github("smwu/baysc")
library(baysc)

# Load additional packages for this vignette
library(ggplot2)
library(tidyr)
library(stats)
```

```{r, echo = FALSE, results = FALSE, warning = FALSE, message = FALSE}
library(devtools)
load_all()
library(baysc)
library(ggplot2)
library(tidyr)
library(stats)
```

For each individual in a finite population of size $N$, we simulate data for correlated categorical exposure variables that arise from underlying latent class clusters, and a binary outcome that is also associated with the latent class clusters. Data are generated according to the steps listed below. Detailed explanations for each of the steps can be found in Section 2. For all individuals $i$, $i = 1,\ldots, N$:

1)	Simulate a categorical stratifying variable, $S_i$, to split the population into strata.
2)	Simulate latent class membership assignment, $C_i$, that assigns each individual to a latent class. Option to have the distribution of latent classes differ by stratum $S_i$ or other variables.
3)	Simulate the $J$-variate categorical exposure, $\boldsymbol{X_{i}} = (X_{i1},\ldots, X_{iJ})$, depending on the latent class assignment $C_i$. Option to have $\boldsymbol{X_{i}}$ also depend on $S_i$. 
4)	Simulate the binary outcome $Y_i$ depending on latent class assignment $C_i$. Option to have $Y$ be clustered. Additional option to have $Y_i$ also depend on $S_i$ or on other variables that are provided. 

To run the population simulation using the default settings (explained in Section 2 below), run the following code. We choose not to save the results to an external file for the purposes of this vignette. 
```{r}
sim_pop <- simulate_pop(save_res = FALSE)
```

After the population is generated, we can use the `simulate_samp` function to create a sample from the population, with the option to have the sample incorporate stratification by $S_i$ as well as one-stage cluster sampling.
```{r}
sim_samp <- simulate_samp(sim_pop = sim_pop, samp_prop = 0.05, strat = TRUE,
                          strat_dist = c(0.5, 0.5), clust = TRUE,
                          samp_seed = 101, save_res = FALSE)
```

Parameters used for `sim_samp()`:

- `sim_pop`: Population simulated using `simulate_pop()`.
- `samp_prop = 0.05`: Sample size as a proportion of the population size. Here, we sample 5\% of the population, resulting in a sample size of 4000. Users can specify the sample size directly instead by using the `samp_size` argument. 
- `strat = TRUE`: Perform stratified sampling by a binary variable $S$. If this is `FALSE`, no stratification occurs during sampling.
- `strat_dist = c(0.5, 0.5)`: The distribution of the two stratum levels of $S$ in the sample. Here, we specify a sampling design where an equal number number of individuals is sampled from both strata. This must sum to 1. 
- `clust = TRUE`: Perform cluster sampling. If `TRUE`, one-stage cluster sampling is performed where clusters are sampled and then all individuals within the cluster are included in the sample. If this is `FALSE`, no cluster sampling is done and individuals are sampled instead.
[ADD ERROR CHECK FOR CLUSTERS!!!!!!!]
- `samp_seed = 101`: Random seed for sampling. 
- `save_res = FALSE`: Results do not need to be saved. If `save_res = TRUE`, `save_path` must also be specified and include both the desired directory and the beginning of the file name for the results. 
In the default data generation settings, the stratifying variable $S$ is associated with the latent class $C$ and outcome $Y$, so that estimation of parameters related to those variables will be biased if survey design is not accounted for.

Once we have the sample data, we can use it as input for the main functions for conducting survey-weighted latent class analysis supervised by an outcome. An overview of the model-fitting, summarizing, and plotting functions is provided in the vignette titled, “An introduction to the baysc package”. 

```{r, warning=FALSE, cache=TRUE, results=FALSE, message = FALSE, eval = FALSE}
# Load simulated data and obtain relevant variables
data_vars <- sim_samp
x_mat <- data_vars$X_data            # Categorical exposure matrix, nxJ
y_all <- c(data_vars$Y_data)         # Binary outcome vector, nx1
cluster_id <- data_vars$cluster_id   # Cluster indicators, nx1
stratum_id <- data_vars$true_Si      # Stratum indicators, nx1
sampling_wt <- data_vars$sample_wt   # Survey sampling weights, nx1
n <- dim(x_mat)[1]                   # Number of individuals
# Probit model only includes latent class
V_data <- NULL # Additional regression covariates
glm_form <- "~ 1"

# Run swolca
res <- swolca(x_mat = x_mat, y_all = y_all, sampling_wt = sampling_wt,
              cluster_id = cluster_id, stratum_id = stratum_id, V_data = V_data,
              run_sampler = "both", glm_form = glm_form, adapt_seed = 1,
              n_runs = 50, burn = 25, thin = 1, update = 20, save_res = FALSE)
       
# Apply variance adjustment to posterior estimates
res_adjust <- swolca_var_adjust(res = res, num_reps = 100, save_res = FALSE, 
                                adjust_seed = 1)      
```

# Population data generation details
We describe the data generation process in detail, using the default argument values as an example. Alternatives from the default values are described in section 2.6. 

## Specify `N`, `H`, and `N_s` parameters for population size and simulating categorical stratifying variable $S_i$. 
We generate data for a population of $N=80000$ individuals. There are $H=2$ stratum in the population defined by binary variable $S_i$ that can take on 1 or 2. We set 60,000 individuals to have $S_i=1$ and 20,000 individuals to have $S_i=2$, using the argument `N_s`, which must have length equal to the number of strata, $H = 2$. An example of a stratifying variable $S$ is residence in two different states.

```{r}
N = 80000; H = 2; N_s = c(60000, 20000)
```

##	Specify `K`, `formula_c`, and `beta_mat_c` parameters for simulating categorical latent class assignment, $C_i$
We define a total of $K=3$ latent classes such that assignment variable $C_i$ takes on values 1, 2, or 3. We also specify $C_i$ to depend on $S_i$ by setting `formula_c = "~ s_all"`. This allows the distribution of the latent classes to differ by strata. Other options for variables influencing $C_i$ are provided in Section 2.6.1.

```{r}
K <- 3
formula_c <- "~ s_all"
```

$C_i$ is generated using a multinomial logistic regression, also known as a baseline category logit model, dependent on variables that influence latent class membership (e.g., $S_i$ in the default setting). Define class membership probabilities to be $\pi_{ik} := P(C_i = k| S_i)$, $k=1,\ldots, K$, with the constraints that the $\pi_{ik}$'s are greater than 0 and sum to 1. Note that $\pi_{ik}$ is equal to the stratum-specific class membership probabilities $\pi_{hk} := P(C_i=k|S_i=h)$, depending on whichever stratum $h$ is the observed value for $S_i$. The corresponding multinomial logistic regression formulation is
$$
\begin{align*} 
&C_i|S_i \sim \text{Multinomial}(1, \pi_{i1},\ldots, \pi_{iK}),\text{ where } \\
&\log\Big(\frac{\pi_{ik}}{\pi_{i1}}\Big)= \beta_{k0} + \beta_{k1}I(S_i=2) \text{ for } k = 2,\ldots, K,\text{with }\\
&\pi_{i1} = \frac{1}{1+\sum\limits_{k=2}^K e^{\beta_{k0} + \beta_{k1}I(S_i=2)}} \text{ and }
\pi_{ik} = \frac{e^{\beta_{k0}+\beta_{k1}I(S_i=2)}}{1+\sum\limits_{k=2}^K e^{\beta_{k0} + \beta_{k1}I(S_i=2)}} \text{ for } k = 2,\ldots, K. 
\end{align*}
$$
For each class $k$, $\beta_{k0}+ \beta_{k1} I(S_i=2)$ models the dependence of $C_i$ on $S_i$ with the following parameter interpretations:

- $\exp(\hat{\beta}_{k0})$: Odds of $C_i=k$ instead of $C_i=1$ among those with $S_i=1$ is $\exp(\hat{\beta}_{k0})$.
- $\exp(\hat{\beta}_{k1})$: Odds of $C_i=k$ instead of $C_i=1$ among those with $S_i=2$ is $\exp(\hat{\beta}_{k1})$ times the odds among those with $S_i=1$.

Let $Q$ denote the number of coefficients for each class $k$, equal to 2 here. Users can either specify the $K\times Q$ $\beta$ matrix directly for the input argument `beta_mat_c`. Below is the $\beta$ matrix for the default setting. Note that the $\beta$'s for $k=1$ are always set to 0.
$$
\begin{pmatrix}\beta_{10} &\beta_{11}\\ \beta_{20} & \beta_{21} \\ \beta_{30}  & \beta_{31} \end{pmatrix} = \begin{pmatrix}0 &0\\ 0.5 & 1.3 \\ -0.4 & 1.5\end{pmatrix}.
$$
Alternatively, it is often easier to specify the class membership probabilities for each level of a categorical variable. For example we can set the class membership probabilities to be $(\pi_{i1}, \pi_{i2}, \pi_{i3}) = (0.3, 0.5, 0.2)$ for those with $S_i=1$ and $(\pi_{i1}, \pi_{i2}, \pi_{i3}) = (0.1, 0.6, 0.3)$ for those with $S_i=2$. This gives overall class membership probabilities of $(\pi_1,\pi_2,\pi_3) = (0.250, 0.525, 0.225)$ given the distribution of strata in the population. Using these class membership probabilities, we can obtain the corresponding $\beta$ matrix using the function `get_betas_c()`. This function is only available for when $C_i$ depends on a single categorical variable. For other situations, see Section 2.6.1. 

```{r}
# Number of latent classes and number of levels of S
K <- 3; H <- 2
# Formula specifying that C depends on S
formula_c <- "~ s_all"
# Dataframe with unique values of S
V_unique <- data.frame(s_all = as.factor(1:H))
# Matrix of class assignment probabilities for each level of S
pi_mat <- matrix(c(0.3, 0.5, 0.2,   # class membership probs for S=1
                   0.1, 0.6, 0.3),  # class membership probs for S=2
                 byrow = TRUE, nrow = H, ncol = K)
# Get matrix of betas for generating C
beta_mat_c <- get_betas_c(pi_mat = pi_mat, formula_c = formula_c, V_unique = V_unique)
beta_mat_c
```
Row $k$ of `beta_mat_c` corresponds to $\beta_{k0}$ and $\beta_{k1}$. The $\beta$'s for $k=1$ are set to 0 for identifiability reasons.

## Specify `J`, `R`, `formula_x`, and `beta_list_x` parameters for simulating multivariate categorical exposure $\boldsymbol{X_i}$
Next, we simulate the $J$-variate categorical exposure variable, $\boldsymbol{X_{i}}$. Each individual will have categorical exposure data for $J=30$ items that all have $R=4$ levels. We specify $\boldsymbol{X_{i}}$ to depend on $C_i$ by setting `formula_x = "~ c_all"`. This is necessary for linking the exposure data to the underlying latent class assignment such that those in the same latent class have more similar $\boldsymbol{X_{i}}$ values. Other options for variables influencing $\boldsymbol{X_{i}}$ are provided in Section 2.6.2. 

```{r}
J <- 30; R <- 4
formula_x <- "~ c_all"
```

$X_{ij}$ is generated using a multinomial logistic regression dependent on variables that influence the observed exposure variables (e.g., $C_i$ in the default setting). Define the class-specific item level probabilities for item $j$, $j=1,\ldots, J$, to be $\theta_{ijr} := P(X_{ij}=r|C_i)$, with the constraints that the $\theta_{ijr}$'s are greater than 0 and $\sum_{r=1}^R \theta_{ijr} = 1$. Note that $\theta_{ijr}$ is equal to the latent class-specific item level probabilities $\theta_{jkr} := P(X_{ij}=r|C_i=k)$, depending on whichever class $k$ is the observed value for $C_i$, so that $X_{ij$ is more likely to be similar for those with the same class assignment. The corresponding multinomial logistic regression formulation for each itme $j$, $j=1,\ldots, J$, is given by:
$$
\begin{align*}
&X_{ij}|C_i \sim \text{Multinomial}(1, \theta_{ij1},\ldots, \theta_{ijR}),\text{ where } \\
&\log\bigg(\frac{\theta_{ijr}}{\theta_{ij1}}\bigg) = \beta_{jr0} + \beta_{jr1}I(C_i=2) + \beta_{jr2}I(C_i=3) \text{ for } r=1,\ldots, R, \text{ with}\\
&\theta_{ij1} = \frac{1}{1+\sum\limits_{r=2}^R e^{\beta_{jr0} + \beta_{jr1}I(C_i=2) + \beta_{jr2}I(C_i=3)}}\text{ and }\
\theta_{ijr} = \frac{e^{\beta_{jr0} + \beta_{jr1}I(C_i=2) + \beta_{jr2}I(C_i=3)}}{1+\sum\limits_{r=2}^R e^{\beta_{jr0} + \beta_{jr1}I(C_i=2) + \beta_{jr2}I(C_i=3)}} \text{ for } r= 2,\ldots, R. 
\end{align*}
$$
Each item $j$ has its own $\beta$ matrix, so for each item $j$ and exposure level $r$, $\beta_{jr0} + \beta_{jr1}I(C_i=2) + \beta_{jr2}I(C_i=3)$ models the dependence of $\boldsymbol{X}_i$ on $C_i$ with the following parameter interpretations:

- $\exp(\hat{\beta}_{jr0})$: Odds of $X_{ij}=r$ instead of $X_{ij}=1$ among those with $C_i=1$ is $\exp(\hat{\beta}_{r0})$.
- $\exp(\hat{\beta}_{jr1})$: Odds of $X_{ij}=r$ instead of $X_{ij}=1$ among those with $C_i=2$ is $\exp(\hat{\beta}_{k1})$ times the odds among those with $C_i=1$.
- $\exp(\hat{\beta}_{jr2})$: Odds of $X_{ij}=r$ instead of $X_{ij}=1$ among those with $C_i=3$ is $\exp(\hat{\beta}_{k1})$ times the odds among those with $C_i=1$.

It is difficult to directly specify a list of $R x K$ $\beta$ matrices, one for each item $j$. Therefore, we instead specify the item level probabilities for each class $k$. First, we define each of the $K=3$ latent classes to have a corresponding pattern profile consisting of a true level for each of the $J$ items. The pattern profiles are displayed below.

```{r, echo = FALSE, fig.width = 2.7, fig.height = 5, fig.align = 'center'}
data("sim_data")
mode_item_probs <- as.data.frame(sim_data$true_global_patterns)
item_labels <- 1:sim_data$J
class_labels <- 1:sim_data$true_K
categ_labels <- 1:sim_data$R
rownames(mode_item_probs) <- item_labels
colnames(mode_item_probs) <- class_labels
mode_item_probs$Item <- rownames(mode_item_probs)
item_title <- "Item"
categ_title <- "Level"
class_title <- "Latent Class"
mode_plot <- mode_item_probs %>% tidyr::gather("Class", "Level", -Item) 
mode_plot %>% ggplot2::ggplot(ggplot2::aes(x=Class, y=factor(Item, levels = rev(item_labels)), 
                                           fill = factor(Level))) + 
  ggplot2::geom_tile(color="black", linewidth = 0.3) + 
  ggplot2::scale_fill_brewer(type="seq", palette="RdYlBu", direction = -1,
                             name = categ_title, labels = categ_labels) +
  ggplot2::labs(x = class_title, y = item_title) +
  ggplot2::theme_classic() + ggplot2::scale_x_discrete() + 
  ggplot2::theme(axis.text.x = ggplot2::element_text(size = 9, color = "black"), 
                 axis.text.y = ggplot2::element_text(size = 9, color = "black"),
                 axis.title.x = ggplot2::element_text(size = 10, color = "black", face = "bold"),
                 axis.title.y = ggplot2::element_text(size = 10, color = "black", face = "bold"),
                 legend.title = ggplot2::element_text(size = 10, color = "black", face = "bold"),
                 legend.text = ggplot2::element_text(size = 9, color = "black"),
                 legend.position = "top")
```

Next, we specify the item level probabilities, $\theta_{ijr}$, that correspond to the pattern profiles by setting the probability of observing the true level to be 0.85, passing in input argument `modal_theta_prob = 0.85`. The probability of observing the three remaining levels will be 0.05 each so that all the probabilities add up to 1. As an example using the pattern profiles displayed above, for those assigned to latent class 3 (i.e., $C_i=3$), for item 1, we have $(\theta_{i11}, \theta_{i12}, \theta_{i13}, \theta_{i14}) = (0.05, 0.05, 0.85, 0.05)$. We can control how likely the true value is by setting the `modal_theta_prob` input argument to different values between 0 and 1, with higher values indicating stronger patterns. Generally, we want this value to be above 0.5 or else patterns will be too weak to detect. 

Using these item level probabilities, we can obtain the corresponding list of $\beta$ matrices for all items by using the function `get_betas_x()`. 

```{r}
# Number of items, exposure levels, latent classes
J <- 30; R <- 4; K <- 3
# Formula specifying that X depends on C
formula_x <- "~ c_all"
# Dataframe with unique values of X
V_unique <- data.frame(c_all = as.factor(1:K))
# Matrix of pattern profiles for each latent class
profiles <- as.matrix(data.frame(C1 = c(rep(1, times = 0.5 * J), 
                                        rep(3, times = 0.5 * J)),
                                 C2 = c(rep(4, times = 0.2 * J), 
                                        rep(2, times = 0.8 * J)),
                                 C3 = c(rep(3, times = 0.3 * J), 
                                        rep(4, times = 0.4 * J),
                                        rep(1, times = 0.3 * J))))
# True level probability
modal_theta_prob <- 0.85
# Get matrix of betas for generating C
beta_list_x <- get_betas_x(profiles = profiles, R = R, 
                           modal_theta_prob = modal_theta_prob, 
                           formula_x = formula_x, V_unique = V_unique)
# Beta matrix for item j=1
beta_list_x[[1]]
```

Row $r$ of `beta_mat_x[[j]]` corresponds to $\beta_{jr0}, \beta_{jk1}, \beta_{jk2}$ for each item $j$. The $\beta$'s for $r=1$ are set to 0 for identifiability reasons.

## Specify `formula_y`, `beta_vec_y`, and `cluster_size` parameters for simulating binary outcome $Y$
Each individual with have a binary outcome $Y_i$ taking on values 0 or 1. We specify $Y_i$ to depend on latent class $C_i$, stratum variable $S_i$, and their interaction, by setting `formula_y = "~ c_all * s_all"`. This induces associations between the latent classes and the outcome, between the strata and the outcome, and the latent class-outcome association is modified by stratum. Other options for variables influencing $Y$ are provided in Section 2.6.3.

```{r}
formula_y = "~ c_all * s_all"
```

$Y_i$ is generated using a probit regression dependent on the variables that influence the outcome (e.g., $C_i$, $S_i$, and $C_i:S_i$ in the default setting). Define the regression parameters to be $\xi_{iq}$ where $\beta$ are the regression coefficient parameters: And let $\Phi$ denote the cumulative density function of the standard Normal distribution. The corresponding probit regression formulation is
$$
\begin{align*}
Y_i|C_i, S_i &\sim \text{Bernoulli}\big(P(Y_i=1|C_i,S_i)\big) \text{, where }\\
P(Y_i=1|C_i, S_i) &= \Phi\Big\{\beta_{i0} + \beta_{i1}I(C_i=2) + \beta_{i2}I(C_i=3) + \beta_{i3}I(S_i=2)\\
&\qquad + \beta_{i4}I(C_i=2, S_i=2) + \beta_{i5}I(C_i=3, S_i=2)\Big\}.
\end{align*}
$$

To ensure the $\beta$ coefficients are in the correct order, we can run the following code to obtain the order of terms mandated by `formula_y`. 

```{r}
# Number of latent classes and strata
K <- 3; H <- 2
# Formula specifying that Y depends on C, S, and their interaction
formula_y <- "~ c_all * s_all"
# Dataframe with unique combinations of C and S
V_unique <- expand.grid(c_all = as.factor(1:K), s_all = as.factor(1:H))
# Design matrix
design_mat_y <- stats::model.matrix(stats::as.formula(formula_y), data = V_unique)
colnames(design_mat_y)
```

For the default example, we specify the $\beta$ vector to be as follows:  

```{r}
beta_vec_y <- c(1, -0.7, -1.5, -0.5, -0.5, -0.3)
```

We can see that these $\beta$ values correspond to approximate outcome probabilities of 0.84, 0.62, and 0.31 for $C=1,2,3$, respectively, among those with $S=1$, and to 0.69, 0.24, and 0.1 for those with $S=2$. We do this by first converting the $\beta$’s from reference cell coding format to mixture reference coding format, and the converting them to the probability of the outcome. Note that this only works for categorical covariates. See @wu2023derivation for more information about mixture reference coding. 

```{r}
# Get number of regression covariates, excluding class assignment C
q <- length(which(!grepl("c_all", colnames(design_mat_y))))
# Convert to mixture reference coding
xi_vec_y <- convert_ref_to_mix(K = K, q = 2, est_beta = beta_vec_y)$est_xi
# Convert to outcome probabilities
convert_to_probs(est_xi = xi_vec_y, glm_form = "~s_all", 
                 V_data = data.frame(s_all = factor(1:2)), cov_name = "s_all")
```

If `xi_vec_y` is known, users can provide it as an input argument to `simulate_pop()` instead of providing `beta_vec_y`. 
$$
\begin{align*}
    \mathbb{E}(y_i|c_i, v_i) &= \Phi\Big\{\xi_{11}I(c_i=1) + \xi_{12}I(c_i=1)v_i \\
    &\quad + \xi_{21}I(c_i=2) + \xi_{22}I(c_i=2)v_i\\
    &\quad + \xi_{31}I(c_i=3) + \xi_{32}I(c_i=3)v_i\Big\}.
\end{align*}
$$

We also introduce clustering in the outcome by specifying the `cluster_size` argument to be greater than 1. By default, we have clusters of size `cluster_size = 80`. Clusters are created with correlated values of $Y_i$ among all those in the same cluster. This clustering is created using R package `SimCorMultRes` version 1.8.0 [@touloumis2016simulating]. Each cluster is composed of 80 individuals, and the latent within-cluster correlation matrix is assumed to be exchangeable with 0.5 on the off-diagonals.

```{r}
cluster_size <- 80
```


## Putting it all together: default scenario
Below, we show the overall pipeline combining all the steps in Sections 2.1 to 2.4 that describe, in detail, the default values that are assumed in the `simulate_pop()` function that was used in the Introduction. 

```{r}
# Population size and strata dimensions
N = 80000; H = 2; N_s = c(60000, 20000)

# Generate C ~ S
K <- 3  
formula_c <- "~ s_all"
V_unique <- data.frame(s_all = as.factor(1:H))
pi_mat <- matrix(c(0.3, 0.5, 0.2,   
                   0.1, 0.6, 0.3), 
                 byrow = TRUE, nrow = H, ncol = K)
beta_mat_c <- get_betas_c(pi_mat = pi_mat, formula_c = formula_c, 
                          V_unique = V_unique)

# Generate X ~ C
J <- 30; R <- 4
formula_x <- "~ c_all"
V_unique <- data.frame(c_all = as.factor(1:K))
profiles <- as.matrix(data.frame(C1 = c(rep(1, times = 0.5 * J), 
                                        rep(3, times = 0.5 * J)),
                                 C2 = c(rep(4, times = 0.2 * J), 
                                        rep(2, times = 0.8 * J)),
                                 C3 = c(rep(3, times = 0.3 * J), 
                                        rep(4, times = 0.4 * J),
                                        rep(1, times = 0.3 * J))))
modal_theta_prob <- 0.85
beta_list_x <- get_betas_x(profiles = profiles, R = R, 
                           modal_theta_prob = modal_theta_prob, 
                           formula_x = formula_x, V_unique = V_unique)

# Generate Y ~ C + S + C:S
formula_y <- "~ c_all * s_all"
beta_vec_y <- c(1, -0.7, -1.5, -0.5, -0.5, -0.3)
cluster_size <- 80

# Simulate population
pop_seed <- 1  # Set seed
sim_pop <- simulate_pop(N = N, J = J, K = K, R = R, N_s = N_s,
                        modal_theta_prob = modal_theta_prob, 
                        formula_c = formula_c, formula_x = formula_x, 
                        formula_y = formula_y, beta_mat_c = beta_mat_c, 
                        beta_list_x = beta_list_x, beta_vec_y = beta_vec_y, 
                        cluster_size = cluster_size, 
                        pop_seed = pop_seed, save_res = FALSE)

# Get sample
sim_samp <- simulate_samp(sim_pop = sim_pop, samp_prop = 0.05, strat = TRUE,
                          strat_dist = c(0.5, 0.5), clust = TRUE,
                          samp_seed = 101, save_res = FALSE)
```


# Alternative options 
To demonstrate alternative options for data generation, we begin by creating two additional variables: 1) a continuous variable, $A_i$, normally distributed with mean 0 and standard deviation 5; and 2) a binary variable, $B_i$, taking on values 1 or 2, with probability of value 2 set to 0.3. Both of these variables should be included in a dataframe as part of the `V_additional` input argument for the `simulate_pop()` function. 

```{r}
# Continuous variable A for age centered about 0
a_all <- stats::rnorm(n = N, mean = 0, sd = 5)
# Binary variable B for physically inactive or active
b_all <- as.factor(stats::rbinom(n = N, size = 1, prob = 0.3) + 1)
# Create dataframe of additional variables A and B
V_additional <- data.frame(a_all, b_all)   
```

##	Alternative options for variables influencing $C_i$

We can choose to generate $C_i$ independently of other variables by setting `formula_c = "~1"` and `V_unique = NULL`.
```{r}
K <- 3
formula_c <- "~ 1"
V_unique <- NULL
pi_mat <- matrix(c(0.3, 0.5, 0.2), 
                 byrow = TRUE, nrow = 1, ncol = K)
beta_mat_c <- get_betas_c(pi_mat = pi_mat, formula_c = formula_c, 
                          V_unique = V_unique)
```

We can also choose to generate $C_i$ dependent not only on $S_i$ but also on additional variables defined in `V_additional`. As an example, we set `formula_c = "~ s_all + a_all"` and have $C_i$ depend on $S_i$ as well as the continuous variable $A_i$. 
$$
\log\Big(\frac{\pi_{ik}}{\pi_{i1}}\Big)= \beta_{k0} + \beta_{k1}I(S_i=2) + \beta_{k2}A_i, \quad k = 2,\ldots, K\\
$$
The `get_betas_c()` function can only be used when $C$ depends on a single categorical variable, so it cannot be used in this case. Instead, we have to specify the $\beta_{k2}$ values by hand and manually add them into the `beta_mat_c` matrix. The interpretation for $\beta_{k2}$ is: the odds of $C_i=k$ instead of $C_i=1$ changes by a factor of $\exp(\beta_{k2})$ for a 1-unit increase in $A_i$, for all levels of $S_i$. For this example, we set $\beta_{22} = \beta_{32} = 0.1$, so the odds of $C_i=2$ instead of $C_i=1$ increases by a factor of $\exp(0.1)\approx 1.11$ for each 1-unit increase in $A_i$, and the equivalent is true for $C_i=3$. $\beta_{12}=0$ for identifiability. Starting with the `beta_mat_c` from Section 2.2, we have

```{r}
# Generate beta_mat_c as in Section 2.2
K <- 3; H <- 2
formula_c <- "~ s_all"
V_unique <- data.frame(s_all = as.factor(1:H))
pi_mat <- matrix(c(0.3, 0.5, 0.2,   # class membership probs for S=1
                   0.1, 0.6, 0.3),  # class membership probs for S=2
                 byrow = TRUE, nrow = H, ncol = K)
beta_mat_c <- get_betas_c(pi_mat = pi_mat, formula_c = formula_c, V_unique = V_unique)

# Add in coefficients for A, updating formula_c and beta_mat_c
formula_c <- "~ s_all + a_all"
beta_mat_c <- cbind(beta_mat_c, a_all = c(0, 0.1, 0.1))
beta_mat_c
```
To check what the corresponding true class membership probabilities $\pi_{ik}$ are, we can use the function `get_categ_probs()`. To do this, we must specify a dataframe of unique covariate values for which we are interested in evaluating the class membership probabilities. We choose to use all levels of $S_i$ as well as the 25th percentile, median, and 75th percentile for $A_i$. 

```{r}
summ_a_all <- round(stats::quantile(V_additional$a_all, c(0.25, 0.5, 0.75)), 3)
V_unique <- as.data.frame(expand.grid(s_all = as.factor(1:H), a_all = summ_a_all))
get_categ_probs(beta_mat = beta_mat_c, formula = formula_c, V_unique = V_unique)
```
We can see that rows 3 and 4, which have $a_all$ at its median, around 0, have class membership probabilities similar to those that were specified in `pi_mat` and used to generate the original `beta_mat_c` without inclusion of $A_i$. As the value of $A_i$ increases to 3.398, the probability of $C_i=2$ or $C_i=3$ also increases, as to be expected based on the specified $\beta_{22}$ and $\beta_{23}$ values. 

##	Alternative options for variables influencing $\boldsymbol{X}_i$

We can choose to generate $X_i$ to be dependent on not only $C_i$ but also stratum variable $S_i$ and/or additional variables defined in `V_additional`. As an example, we set `formula_x = "~ c_all + s_all"` and have $\boldsymbol{X}_i$ depend on underlying latent classes $C_i$ as well as binary stratum variable $S_i$. 
$$
\log\bigg(\frac{\theta_{ijr}}{\theta_{ij1}}\bigg)= \beta_{jr0} + \beta_{jr1}I(C_i=2) + \beta_{jr2}I(C_i=3) + \beta_{jr3}I(S_i=2), \quad r = 2,\ldots, R\\
$$
We specify the $\beta_{jr3}$ values by hand and manually add them into the `beta_list_x` list. The interpretation for $\beta_{jr3}$ is: the odds of $X_{ij}=r$ instead of $X_{ij}=1$ changes by a factor of $\exp(\beta_{jr3})$ for those with $S_i=2$ compared to those with $S_i=1$, for all levels of $C_i$. For this example, we set $\beta_{j23} =0.5$ and $\beta_{j33} = \beta_{j24}=0$ for all $j=1,\ldots, J$, so the odds of $X_{ij}=2$ instead of $X_{ij}=1$ increases by a factor of $\exp(0.5)\approx 1.65$ for those with $S_i=2$ instead of $S_i=1$, but the odds are unchanged for $X_{ij}=3$ and $X_{ij}=4$. $\beta_{j13}=0$ for identifiability. Starting with the `beta_list_x` from Section 2.3, we have

```{r}
# Generate beta_list_x as in Section 2.3
J <- 30; R <- 4; K <- 3
formula_x <- "~ c_all"
V_unique <- data.frame(c_all = as.factor(1:K))
profiles <- as.matrix(data.frame(C1 = c(rep(1, times = 0.5 * J), 
                                        rep(3, times = 0.5 * J)),
                                 C2 = c(rep(4, times = 0.2 * J), 
                                        rep(2, times = 0.8 * J)),
                                 C3 = c(rep(3, times = 0.3 * J), 
                                        rep(4, times = 0.4 * J),
                                        rep(1, times = 0.3 * J))))
modal_theta_prob <- 0.85
beta_list_x <- get_betas_x(profiles = profiles, R = R, 
                           modal_theta_prob = modal_theta_prob, 
                           formula_x = formula_x, V_unique = V_unique)

# Add in coefficients for S to each j matrix, updating formula_x and beta_list_x
formula_x <- "~ c_all + s_all"
beta_list_x <- lapply(1:J, function(j) cbind(beta_list_x[[j]], 
                                             s_all = c(0, 0.5, 0, 0)))
beta_list_x[[1]]
```

To check what the corresponding true item level probabilities $\theta_{ijr}$ are, we can use the function `get_categ_probs()`. To do this, we specify a dataframe of unique covariate values for which we are interested in evaluating the class membership probabilities. We choose to use all levels of $C_i$ and $S_i$. Note that this handles the $\beta$ matrix for a single item $j$.  

```{r}
V_unique <- as.data.frame(expand.grid(c_all = as.factor(1:K), s_all = as.factor(1:H)))
get_categ_probs(beta_mat = beta_list_x[[1]], formula = formula_x, V_unique = V_unique)
```
We can see that rows 1 to 3, which have $s_all$ at its reference value of 1, have item level probabilities the same as the case without inclusion of $S_i$. For rows 4 to 6, for which $s_all$ is 2, the probability of $X_{ij}=2$ increases, as to be expected based on the specified $\beta_{j23}$ value. 

## Alternative options for $Y_i$ 

We can choose to have no clustering in the outcome by specifying the `cluster_size` argument to be 1. 

```{r}
cluster_size <- 1
```

We can also choose to generate $Y_i$ to be dependent on additional variables. For example, if we want to include binary variable $B_i$ taking on value 1 or 2, we set `formula_y = "~ c_all * (s_all + b_all)"`. Note that the model must include all interaction terms of the additional variables with $c_all$. This is due to how the model handles label switching during the MCMC sampler. 

$$
\begin{align*}
P(Y_i=1|C_i, S_i, B_i) &= \Phi\Big\{\beta_{i0} + \beta_{i1}I(C_i=2) + \beta_{i2}I(C_i=3)  + \beta_{i3}I(S_i=2) + \beta_{i4}I(B_i=2)\\
&\qquad + \beta_{i5}I(C_i=2, S_i=2) + \beta_{i6}I(C_i=3, S_i=2)\\
&\qquad + \beta_{i7}I(C_i=2, B_i=2) + \beta_{i8}I(C_i=3, B_i=2) \Big\}.
\end{align*}
$$
We specify the $\beta_{i4}$, $\beta_{i7}$, and $\beta_{i8}$ values by hand and manually add them into the `beta_vec_y` vector. The interpretation for $\beta_{i4}$ is: the z-score of $Y_i$ changes by a factor of $\beta_{i4}$ for those with $B_i=2$ compared to those with $B_i=1$, for $C_i=1$ and for all levels of $S_i$. The interpretation of $\beta_{i7}$ is: the difference between how the z-score of $Y_i$ changes for those with $C_i=2$ vs. $C_i=1$ changes by $\beta_{i7}$ for those with $B_i=2$ compared to those with $B_i=1$. A similar interepretation holds for $\beta_{i8}$. For this example, we set $\beta_{i4} = 0.3$ and $\beta_{i7}=\beta_{i8}=0$. Starting with the `beta_vec_y` from Section 2.4, we have

```{r}
# beta_vec_y as in Section 2.4
beta_vec_y <- c(1, -0.7, -1.5, -0.5, -0.5, -0.3)
# Add in coefficients for B, updating formula_y and beta_vec_y
# Be careful about the order of the coefficients
formula_y <- "~ c_all * (s_all + b_all)"
beta_vec_y <- c(1, -0.7, -1.5, -0.5, 0.3, -0.5, -0.3,  0, 0)
```

Check that the order specified in `beta_vec_y` is correct:
```{r}
# Dataframe with unique combinations of C, S, and B
V_unique <- expand.grid(c_all = as.factor(1:K), s_all = as.factor(1:H), 
                        b_all = as.factor(1:2))
# Design matrix
design_mat_y <- stats::model.matrix(stats::as.formula(formula_y), data = V_unique)
colnames(design_mat_y)
```

## Putting it all together: alternative scenario

```{r}
# Population size and strata dimensions
N = 80000; H = 2; N_s = c(60000, 20000)

# Create dataframe of additional variables A and B
a_all <- stats::rnorm(n = N, mean = 0, sd = 5)
b_all <- as.factor(stats::rbinom(n = N, size = 1, prob = 0.3) + 1)
V_additional <- data.frame(a_all, b_all)   

# Generate C ~ S + A
K <- 3  
formula_c_temp <- "~ s_all"
V_unique <- data.frame(s_all = as.factor(1:H))
pi_mat <- matrix(c(0.3, 0.5, 0.2,   # class membership probs for S=1
                   0.1, 0.6, 0.3),  # class membership probs for S=2
                 byrow = TRUE, nrow = H, ncol = K)
beta_mat_temp <- get_betas_c(pi_mat = pi_mat, formula_c = formula_c_temp, 
                             V_unique = V_unique)
formula_c <- "~ s_all + a_all"
beta_mat_c <- cbind(beta_mat_temp, a_all = c(0, 0.1, 0.1))

# Generate X ~ C + S
J <- 30; R <- 4
formula_x_temp <- "~ c_all"
V_unique <- data.frame(c_all = as.factor(1:K))
profiles <- as.matrix(data.frame(C1 = c(rep(1, times = 0.5 * J), 
                                        rep(3, times = 0.5 * J)),
                                 C2 = c(rep(4, times = 0.2 * J), 
                                        rep(2, times = 0.8 * J)),
                                 C3 = c(rep(3, times = 0.3 * J), 
                                        rep(4, times = 0.4 * J),
                                        rep(1, times = 0.3 * J))))
modal_theta_prob <- 0.85
beta_list_x_temp <- get_betas_x(profiles = profiles, R = R, 
                               modal_theta_prob = modal_theta_prob, 
                               formula_x = formula_x_temp, V_unique = V_unique)
formula_x <- "~ c_all + s_all"
beta_list_x <- lapply(1:J, function(j) cbind(beta_list_x_temp[[j]], 
                                             s_all = c(0, 0.5, 0, 0)))

# Generate Y ~ C + S + B + C:S + B:S, with no clustering
formula_y <- "~ c_all * (s_all + b_all)"
beta_vec_y <- c(1, -0.7, -1.5, -0.5, 0.3, -0.5, -0.3,  0, 0)
cluster_size <- 1

# Simulate population
pop_seed <- 1  # Set seed
sim_pop <- simulate_pop(N = N, J = J, K = K, R = R, N_s = N_s,
                        V_additional = V_additional, 
                        modal_theta_prob = modal_theta_prob, 
                        formula_c = formula_c, formula_x = formula_x, 
                        formula_y = formula_y, beta_mat_c = beta_mat_c, 
                        beta_list_x = beta_list_x, beta_vec_y = beta_vec_y, 
                        cluster_size = cluster_size, 
                        pop_seed = pop_seed, save_res = FALSE)

# Get sample, with no clustering
sim_samp <- simulate_samp(sim_pop = sim_pop, samp_prop = 0.05, strat = TRUE,
                          strat_dist = c(0.5, 0.5), clust = FALSE,
                          samp_seed = 101, save_res = FALSE)

```



